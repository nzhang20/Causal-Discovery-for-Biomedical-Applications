{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a454244-37ff-4d14-946e-e5d985498799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data processing imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#model imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc1a2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcos_data = pd.read_csv(\"C:/Users/Mariana/UCSD/DSC180B/Causal-Discovery-on-Gut-Microbial-Data-for-Disease-Risk-Prediction/data/clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcos_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e8e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pcos_data.drop(columns=[\"Unnamed: 0\", \"region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31f5300",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"group\"]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fee7603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['group'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296a0d87-7059-4846-b68b-9a626a0b15d5",
   "metadata": {},
   "source": [
    "Model Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d08c9b-3cb2-4b13-8e2b-8870073aed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Encoder f_enc to map X → [Z1, Z2]\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc_mu = nn.Linear(input_dim, latent_dim)\n",
    "        self.fc_sigma = nn.Linear(input_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_mu = self.fc_mu(x)\n",
    "        z_sigma = torch.exp(0.5 * self.fc_sigma(x))\n",
    "        z = z_mu + z_sigma * torch.randn_like(z_sigma)\n",
    "        return z, z_mu, z_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1fa6476-91e5-4e38-966a-31a904ad8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Decoder f_dec to map [Z1, Z2] → X'\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, output_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.fc(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56a4f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flow model\n",
    "class FlowModel(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(FlowModel, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, latent_dim)  #invertible layer\n",
    "    \n",
    "    def forward(self, z_s):\n",
    "        return self.fc(z_s)\n",
    "\n",
    "    def inverse(self, z_s):\n",
    "        weight = self.fc.weight\n",
    "        bias = self.fc.bias\n",
    "\n",
    "        if z_s.shape[-1] != weight.shape[0]:\n",
    "            raise ValueError(f\"z_s dimensions {z_s.shape[-1]} do not match weight dimensions {weight.shape[0]}\")\n",
    "\n",
    "        weight_inv = torch.linalg.inv(weight)\n",
    "        z_s_tilde = (z_s - bias) @ weight_inv.T\n",
    "        return z_s_tilde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dae441a-4c85-4284-8949-67f282aefc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize clasifier f_cls to map Z1 → Y\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes=2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, num_classes)\n",
    "\n",
    "    def forward(self, z_c, z_s_tilde):\n",
    "        z_combined = torch.cat([z_c, z_s_tilde], dim=-1)\n",
    "        return self.fc(z_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc68bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b33fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))\n",
    "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f756bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set dataset dimensions\n",
    "input_dim = X_train.shape[1]\n",
    "latent_dim = 50\n",
    "z_dim_c = 10\n",
    "z_dim_s = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec36bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set training params\n",
    "num_epochs = 20\n",
    "alpha1 = 0.01\n",
    "alpha2 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b2e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "encoder = Encoder(input_dim, latent_dim)\n",
    "decoder = Decoder(latent_dim, input_dim)\n",
    "flow_model = FlowModel(z_dim_s)\n",
    "classifier = Classifier(latent_dim, num_classes=2)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + \n",
    "    list(decoder.parameters()) + \n",
    "    list(flow_model.parameters()) + \n",
    "    list(classifier.parameters()), lr=1e-3)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        # Encode\n",
    "        z, z_mu, z_sigma = encoder(x)\n",
    "        z_c, z_s = z[:, :z_dim_c], z[:, z_dim_c:]\n",
    "        \n",
    "        # Decode\n",
    "        x_recon = decoder(z)\n",
    "\n",
    "        # Flow model\n",
    "        z_s_tilde = flow_model.inverse(z_s)\n",
    "        \n",
    "        # Classification\n",
    "        y_pred = classifier(z_c, z_s_tilde)\n",
    "        \n",
    "        # Losses\n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        kl_loss = -0.5 * torch.mean(1 + z_sigma - z_mu**2 - torch.exp(z_sigma))\n",
    "        cls_loss = F.cross_entropy(y_pred, y)\n",
    "        ent_loss = -torch.mean(torch.softmax(y_pred, dim=-1) * torch.log_softmax(y_pred, dim=-1))\n",
    "        \n",
    "        loss = cls_loss + alpha1 * ent_loss + alpha2 * (recon_loss + kl_loss)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f00b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "encoder.eval()\n",
    "classifier.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        z, _, _ = encoder(x_batch)\n",
    "        z_c, z_s = z[:, :z_dim_c], z[:, z_dim_c:]\n",
    "        z_s_tilde = flow_model.inverse(z_s)\n",
    "        y_pred = classifier(z_c, z_s_tilde)\n",
    "        \n",
    "        all_preds.append(torch.argmax(y_pred, dim=1).cpu().numpy())\n",
    "        all_labels.append(y_batch.cpu().numpy())\n",
    "\n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "auc = roc_auc_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
